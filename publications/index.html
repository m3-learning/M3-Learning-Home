<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | M3-Learning </title> <meta name="author" content="Joshua C. Agar"> <meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/al-folio/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/al-folio/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/al-folio/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/al-folio/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://alshedivat.github.io/al-folio/publications/"> <link defer rel="stylesheet" href="/al-folio/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/al-folio/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/al-folio/"> M3-Learning </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/al-folio/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/al-folio/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/al-folio/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/al-folio/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/al-folio/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/al-folio/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/al-folio/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/al-folio/people/">people </a> </li> <li class="nav-item dropdown active"> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus <span class="sr-only">(current)</span> </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item active" href="/al-folio/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/al-folio/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/al-folio/blog/">blog</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p> </header> <article> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/publication_preview/2023WeiArxiv-480.webp 480w,/al-folio/assets/img/publication_preview/2023WeiArxiv-800.webp 800w,/al-folio/assets/img/publication_preview/2023WeiArxiv-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/al-folio/assets/img/publication_preview/2023WeiArxiv.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2023WeiArxiv.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Wei2023-tp" class="col-sm-8"> <div class="title">Low latency optical-based mode tracking with machine learning deployed on FPGAs on a tokamak</div> <div class="author"> Yumou Wei ,  Ryan F Forelli ,  Chris Hansen ,  Jeffrey P Levesque ,  Nhan Tran ,  <em>Joshua C Agar</em> ,  Giuseppe Di Guglielmo ,  Michael E Mauel ,  and  Gerald A Navratil </div> <div class="periodical"> <em></em> Nov 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2312.00128" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/al-folio/assets/pdf/2023WeiArxiv.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-arxiv-id="2312.00128"></span> <span class="__dimensions_badge_embed__" data-doi="10.48550/arXiv.2312.00128" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Active feedback control in magnetic confinement fusion devices is desirable to mitigate plasma instabilities and enable robust operation. Optical high-speed cameras provide a powerful, non-invasive diagnostic and can be suitable for these applications. In this study, we process fast camera data, at rates exceeding 100kfps, on \textit{in situ} Field Programmable Gate Array (FPGA) hardware to track magnetohydrodynamic (MHD) mode evolution and generate control signals in real-time. Our system utilizes a convolutional neural network (CNN) model which predicts the n=1 MHD mode amplitude and phase using camera images with better accuracy than other tested non-deep-learning-based methods. By implementing this model directly within the standard FPGA readout hardware of the high-speed camera diagnostic, our mode tracking system achieves a total trigger-to-output latency of 17.6\mus and a throughput of up to 120kfps. This study at the High Beta Tokamak-Extended Pulse (HBT-EP) experiment demonstrates an FPGA-based high-speed camera data acquisition and processing system, enabling application in real-time machine-learning-based tokamak diagnostic and control as well as potential applications in other scientific domains.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/publication_preview/NPJ2023-480.webp 480w,/al-folio/assets/img/publication_preview/NPJ2023-800.webp 800w,/al-folio/assets/img/publication_preview/NPJ2023-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/al-folio/assets/img/publication_preview/NPJ2023.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="NPJ2023.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Kalinin2023-lz" class="col-sm-8"> <div class="title">Machine learning for automated experimentation in scanning transmission electron microscopy</div> <div class="author"> Sergei V Kalinin ,  Debangshu Mukherjee ,  Kevin Roccapriore ,  Benjamin J Blaiszik ,  Ayana Ghosh ,  Maxim A Ziatdinov ,  Anees Al-Najjar ,  Christina Doty ,  Sarah Akers ,  Nageswara S Rao ,  <em>Joshua C Agar</em> ,  and  Steven R Spurgeon </div> <div class="periodical"> <em>npj Computational Materials</em>, Dec 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.nature.com/articles/s41524-023-01142-0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/al-folio/assets/pdf/npj2023.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1038/s41524-023-01142-0"></span> <span class="__dimensions_badge_embed__" data-doi="10.1038/s41524-023-01142-0" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Machine learning (ML) has become critical for post-acquisition data analysis in (scanning) transmission electron microscopy, (S)TEM, imaging and spectroscopy. An emerging trend is the transition to real-time analysis and closed-loop microscope operation. The effective use of ML in electron microscopy now requires the development of strategies for microscopy-centric experiment workflow design and optimization. Here, we discuss the associated challenges with the transition to active ML, including sequential data analysis and out-of-distribution drift effects, the requirements for edge operation, local and cloud data storage, and theory in the loop operations. Specifically, we discuss the relative contributions of human scientists and ML agents in the ideation, orchestration, and execution of experimental workflows, as well as the need to develop universal hyper languages that can apply across multiple platforms. These considerations will collectively inform the operationalization of ML in next-generation experimentation.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/publication_preview/2023NeurIPSshuyu-480.webp 480w,/al-folio/assets/img/publication_preview/2023NeurIPSshuyu-800.webp 800w,/al-folio/assets/img/publication_preview/2023NeurIPSshuyu-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/al-folio/assets/img/publication_preview/2023NeurIPSshuyu.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2023NeurIPSshuyu.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Qin2023-bn" class="col-sm-8"> <div class="title">Extremely Noisy 4D-TEM Strain Mapping Using Cycle Consistent Spatial Transforming Autoencoders</div> <div class="author"> Shuyu Qin ,  Nhan Tran ,  and  <em>Joshua C Agar</em> </div> <div class="periodical"> Nov 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://openreview.net/pdf?id=7yt3N0o0W9" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/al-folio/assets/pdf/2023NeurIPSshuyu.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi=""></span> <span class="__dimensions_badge_embed__" data-doi="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Atomic-scale imaging of 2D and quantum materials benefits from precisely extracting crystallographic strain, shear, and rotation to understand their mechanical, optical and electronic properties. One powerful technique is 4D-TEM (4-dimensional transmission electron microscopy), where a convergent electron beam is scanned across a sample while measuring the resulting diffraction pattern with a direct electron detector. Extracting the crystallographic strain, shear, and rotation from this data relies either on cross-correlation of probe templates (e.g., implemented in py4DSTEM) or determining the center of mass (CoM) of the diffraction peaks. These algorithms have limitations. They require manual preprocessing and hyperparameter tuning, are sensitive to signal-to-noise, and generally are difficult to automate. There is no one-size-fits-all algorithm. Recently, machine learning techniques have been used to assist in analyzing 4D-TEM data, however, these models do not possess the capacity to learn the strain, rotation, or translation instead they just learn an approximation that almost aways tends to be correct as long as the test examples are within the training dataset distribution. We developed a novel neural network structure – Cycle Consistent Spatial Transforming Autoencoder (CC-ST-AE). This model takes a set of diffraction images and trains a sparse autoencoder to classify an observed diffraction pattern to a dictionary of learned “averaged” diffraction patterns. Secondly, it learns the affine transformation matrix parameters that minimizes the reconstruction error between the dictionary and the input diffraction pattern. Since the affine transformation includes translation, strain, shear, and rotation, we can parsimoniously learn the strain tensor. To ensure the model is physics conforming, we train the model cycle consistently, by ensuring the inverse affine transformation from the dictionary results in the original diffraction pattern. We validated this model on a number of benchmark tasks including: A Simulated 4D TEM data of WS_2 and WSe_2 lateral heterostructures (noise free) with a ground truth of the strain, rotation and shear parameters. Secondly, we test this model on experimental 4D TEM on 2D heterostructures of tungsten disulfide (WS_2) and tungsten diselenide (WSe_2). This model shows several significant improvements including: 1. When tested on simulated data, the model can recover the ground truth with minimal error. 2. The model can learn the rotation and strain on noisy diffraction patterns where CoM failed, and significantly outperforms template matching (py4DSTEM). 3. Our model can accommodate large and continuous rotations difficult to obtain with other methods. 4. Our model is more robust to noisy data. 5. Our model can map the strain, shear and rotation; identify dislocation and ripples; and distinguish background and sample area automatically. Ultimately, this work demonstrates how embedding physical concepts into unsupervised neural networks can simplify, automate, and accelerate analysis pipelines while simultaneously leveraging stochastic averaging that improves robustness on noisy data. This algorithmic concept can be extended to include other physical phenomena (e.g., polarization, sample tilt), can be used in automated experiments, and can be applied to other applications in materials characterization. Detailed information is attached in PDF.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/publication_preview/2023NeurIPSAlibek-480.webp 480w,/al-folio/assets/img/publication_preview/2023NeurIPSAlibek-800.webp 800w,/al-folio/assets/img/publication_preview/2023NeurIPSAlibek-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/al-folio/assets/img/publication_preview/2023NeurIPSAlibek.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2023NeurIPSAlibek.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Kaliyev2023-xz" class="col-sm-8"> <div class="title">Rapid Fitting of Band-Excitation Piezoresponse Force Microscopy Using Physics Constrained Unsupervised Neural Networks</div> <div class="author"> Alibek T Kaliyev ,  Ryan F Forelli ,  Shuyu Qin ,  Yichen Guo ,  Seda Memik ,  Michael W Mahoney ,  Amir Gholami ,  Nhan Tran ,  Philip Harris ,  Martin Takáč ,  and  Joshua Agar </div> <div class="periodical"> Nov 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://openreview.net/pdf?id=ITda7kqxSn" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/al-folio/assets/pdf/2023NeurIPSAlibek.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi=""></span> <span class="__dimensions_badge_embed__" data-doi="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Scanning probe spectroscopy generates high-dimensional data that is difficult to analyze in real time, hindering researcher creativity. Machine learning techniques like PCA accelerate analysis but are inefficient, sensitive to noise, and lack interpretability. We developed an unsupervised deep neural network constrained by a known empirical equation to enable real-time, robust fitting. Demonstrated on band-excitation piezoresponse force microscopy, our model fits cantilever response to a simple harmonic oscillators more than 4 orders of magnitude faster than least squares while enhancing robustness. It performs well on noisy data where conventional methods fail. Quantization-aware training enables sub-millisecond streaming inference on an FPGA, orders of magnitude faster than data acquisition. This methodology broadly applies to spectroscopic fitting and provides a pathway for real-time control and interpretation.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/publication_preview/2023NeuroIPSYichen-480.webp 480w,/al-folio/assets/img/publication_preview/2023NeuroIPSYichen-800.webp 800w,/al-folio/assets/img/publication_preview/2023NeuroIPSYichen-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/al-folio/assets/img/publication_preview/2023NeuroIPSYichen.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2023NeuroIPSYichen.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Guo2023-ab" class="col-sm-8"> <div class="title">Understanding Experimental Data by Identifying Symmetries with Deep Learning</div> <div class="author"> Yichen Guo ,  Shuyu Qin ,  and  Joshua Agar </div> <div class="periodical"> Nov 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://openreview.net/pdf?id=TDhNb2Q9Xm" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/al-folio/assets/pdf/2023NeuroIPYichen.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi=""></span> <span class="__dimensions_badge_embed__" data-doi="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Utilizing computational methods to extract actional information from scientific data is essential due to the time-consuming and inaccurate nature of the manual processes of humans. To better serve the purpose, equipping computational methods with physical rules is necessary. Integrating deep learning models with symmetry awareness has emerged as a promising approach to significantly improve symmetry detection in experimental data, with techniques such as parameter sharing and novel convolutional layers enhancing symmetry recognition.[1,2,3,4,5,6] However, the challenge of integrating physical principles, such as symmetry, into these models persists. To address this, we have developed benchmarking datasets and training frameworks, exploring three perspectives to classify wallpaper group symmetries effectively. Our study demonstrates the limitations of deep learning models in understanding symmetry, as evidenced by benchmark results. A detailed analysis is provided with a hierarchical dataset and training outcomes, while a symmetry filter is designed aiming to improve symmetry operation recognition. This endeavor aims to push the boundaries of deep learning models in comprehending symmetry and embed physical rules within them, ultimately unlocking new possibilities at the intersection of machine learning and physical symmetry, with valuable applications in materials science and beyond.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/publication_preview/2023AdvanceSciMiryam-480.webp 480w,/al-folio/assets/img/publication_preview/2023AdvanceSciMiryam-800.webp 800w,/al-folio/assets/img/publication_preview/2023AdvanceSciMiryam-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/al-folio/assets/img/publication_preview/2023AdvanceSciMiryam.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2023AdvanceSciMiryam.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="OReilly2023-su" class="col-sm-8"> <div class="title">The effect of chemical environment and temperature on the domain structure of free-standing BaTiO3 via in situ STEM</div> <div class="author"> Tamsin O’Reilly ,  Kristina M Holsgrove ,  Xinqiao Zhang ,  John J R Scott ,  Iaro Gaponenko ,  Praveen Kumar ,  Joshua Agar ,  Patrycja Paruch ,  and  Miryam Arredondo </div> <div class="periodical"> <em>Advancement of science</em>, Aug 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://onlinelibrary.wiley.com/doi/10.1002/advs.202303028" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/al-folio/assets/pdf/2023AdvanceSciMiryam.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1002/advs.202303028"></span> <span class="__dimensions_badge_embed__" data-doi="10.1002/advs.202303028" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Ferroelectrics, due to their polar nature and reversible switching, can be used to dynamically control surface chemistry for catalysis, chemical switching, and other applications such as water splitting. However, this is a complex phenomenon where ferroelectric domain orientation and switching are intimately linked to surface charges. In this work, the temperature-induced domain behavior of ferroelectric-ferroelastic domains in free-standing BaTiO3 films under different gas environments, including vacuum and oxygen-rich, is studied by in situ scanning transmission electron microscopy (STEM). An automated pathway to statistically disentangle and detect domain structure transformations using deep autoencoders, providing a pathway towards real-time analysis is also established. These results show a clear difference in the temperature at which phase transition occurs and the domain behavior between various environments, with a peculiar domain reconfiguration at low temperatures, from a-c to a-a at \approx60 °C. The vacuum environment exhibits a rich domain structure, while under the oxidizing environment, the domain structure is largely suppressed. The direct visualization provided by in situ gas and heating STEM allows to investigate the influence of external variables such as gas, pressure, and temperature, on oxide surfaces in a dynamic manner, providing invaluable insights into the intricate surface-screening mechanisms in ferroelectrics.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/publication_preview/2023NPJUrsula-480.webp 480w,/al-folio/assets/img/publication_preview/2023NPJUrsula-800.webp 800w,/al-folio/assets/img/publication_preview/2023NPJUrsula-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/al-folio/assets/img/publication_preview/2023NPJUrsula.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2023NPJUrsula.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Ludacka2023-fo" class="col-sm-8"> <div class="title">Imaging and structure analysis of ferroelectric domains, domain walls, and vortices by scanning electron diffraction</div> <div class="author"> Ursula Ludacka ,  Jiali He ,  Shuyu Qin ,  Manuel Zahn ,  Emil Frang Christiansen ,  Kasper A Hunnestad ,  Zewu Yan ,  Edith Bourret ,  István Kézsmárki ,  Antonius T J Helvoort ,  Joshua Agar ,  and  Dennis Meier </div> <div class="periodical"> <em></em> May 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2305.05727" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/al-folio/assets/pdf/2023NPJUrsula.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-arxiv-id="2305.05727"></span> <span class="__dimensions_badge_embed__" data-doi="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Direct electron detectors in scanning transmission electron microscopy give unprecedented possibilities for structure analysis at the nanoscale. In electronic and quantum materials, this new capability gives access to, for example, emergent chiral structures and symmetry-breaking distortions that underpin functional properties. Quantifying nanoscale structural features with statistical significance, however, is complicated by the subtleties of dynamic diffraction and coexisting contrast mechanisms, which often results in low signal-to-noise and the superposition of multiple signals that are challenging to deconvolute. Here we apply scanning electron diffraction to explore local polar distortions in the uniaxial ferroelectric Er(Mn,Ti)O_3. Using a custom-designed convolutional autoencoder with bespoke regularization, we demonstrate that subtle variations in the scattering signatures of ferroelectric domains, domain walls, and vortex textures can readily be disentangled with statistical significance and separated from extrinsic contributions due to, e.g., variations in specimen thickness or bending. The work demonstrates a pathway to quantitatively measure symmetry-breaking distortions across large areas, mapping structural changes at interfaces and topological structures with nanoscale spatial resolution.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/al-folio/assets/img/publication_preview/2023FastML-480.webp 480w,/al-folio/assets/img/publication_preview/2023FastML-800.webp 800w,/al-folio/assets/img/publication_preview/2023FastML-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/al-folio/assets/img/publication_preview/2023FastML.jpeg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2023FastML.jpeg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Deiana2022-ey" class="col-sm-8"> <div class="title">Applications and Techniques for Fast Machine Learning in Science</div> <div class="author"> Allison Mccarn Deiana ,  Nhan Tran ,  <em>Joshua C Agar</em> ,  Michaela Blott ,  Giuseppe Di Guglielmo ,  Javier Duarte ,  Philip Harris ,  Scott Hauck ,  Mia Liu ,  Mark S Neubauer ,  Jennifer Ngadiuba ,  Seda Ogrenci-Memik ,  Maurizio Pierini ,  Thea Aarrestad ,  Steffen Bahr ,  Jurgen Becker ,  Anne-Sophie Berthold ,  Richard J Bonventre ,  Tomas E Muller Bravo ,  Markus Diefenthaler ,  Zhen Dong ,  Nick Fritzsche ,  Amir Gholami ,  Ekaterina Govorkova ,  Kyle J Hazelwood ,  Christian Herwig ,  Babar Khan ,  Sehoon Kim ,  Thomas Klijnsma ,  Yaling Liu ,  Kin Ho Lo ,  Tri Nguyen ,  Gianantonio Pezzullo ,  Seyedramin Rasoulinezhad ,  Ryan A Rivera ,  Kate Scholberg ,  Justin Selig ,  Sougata Sen ,  Dmitri Strukov ,  William Tang ,  Savannah Thais ,  Kai Lukas Unger ,  Ricardo Vilalta ,  Belinavon Krosigk ,  Thomas K Warburton ,  Maria Acosta Flechas ,  Anthony Aportela ,  Thomas Calvet ,  Leonardo Cristella ,  Daniel Diaz ,  Caterina Doglioni ,  Maria Domenica Galati ,  Elham E Khoda ,  Farah Fahim ,  Davide Giri ,  Benjamin Hawks ,  Duc Hoang ,  Burt Holzman ,  Shih-Chieh Hsu ,  Sergo Jindariani ,  Iris Johnson ,  Raghav Kansal ,  Ryan Kastner ,  Erik Katsavounidis ,  Jeffrey Krupa ,  Pan Li ,  Sandeep Madireddy ,  Ethan Marx ,  Patrick McCormack ,  Andres Meza ,  Jovan Mitrevski ,  Mohammed Attia Mohammed ,  Farouk Mokhtar ,  Eric Moreno ,  Srishti Nagu ,  Rohin Narayan ,  Noah Palladino ,  Zhiqiang Que ,  Sang Eon Park ,  Subramanian Ramamoorthy ,  Dylan Rankin ,  Simon Rothman ,  Ashish Sharma ,  Sioni Summers ,  Pietro Vischia ,  Jean-Roch Vlimant ,  and  Olivia Weng </div> <div class="periodical"> <em>Front Big Data</em>, May 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.3389/fdata.2022.787421"></span> <span class="__dimensions_badge_embed__" data-doi="10.3389/fdata.2022.787421" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>In this community review report, we discuss applications and techniques for fast machine learning (ML) in science-the concept of integrating powerful ML methods into the real-time experimental data processing loop to accelerate scientific discovery. The material for the report builds on two workshops held by the Fast ML for Science community and covers three main areas: applications for fast ML across a number of scientific domains; techniques for training and implementing performant and resource-efficient ML algorithms; and computing architectures, platforms, and technologies for deploying these algorithms. We also present overlapping challenges across the multiple scientific domains where common solutions can be found. This community report is intended to give plenty of examples and inspiration for scientific discovery through integrated and accelerated ML solutions. This is followed by a high-level overview and organization of technical advances, including an abundance of pointers to source material, which can enable these breakthroughs.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Deiana2022-ey</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Applications and Techniques for Fast Machine Learning in Science}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Deiana, Allison Mccarn and Tran, Nhan and Agar, Joshua C and Blott, Michaela and Guglielmo, Giuseppe Di and Duarte, Javier and Harris, Philip and Hauck, Scott and Liu, Mia and Neubauer, Mark S and Ngadiuba, Jennifer and Ogrenci-Memik, Seda and Pierini, Maurizio and Aarrestad, Thea and Bahr, Steffen and Becker, Jurgen and Berthold, Anne-Sophie and Bonventre, Richard J and Bravo, Tomas E Muller and Diefenthaler, Markus and Dong, Zhen and Fritzsche, Nick and Gholami, Amir and Govorkova, Ekaterina and Hazelwood, Kyle J and Herwig, Christian and Khan, Babar and Kim, Sehoon and Klijnsma, Thomas and Liu, Yaling and Lo, Kin Ho and Nguyen, Tri and Pezzullo, Gianantonio and Rasoulinezhad, Seyedramin and Rivera, Ryan A and Scholberg, Kate and Selig, Justin and Sen, Sougata and Strukov, Dmitri and Tang, William and Thais, Savannah and Unger, Kai Lukas and Vilalta, Ricardo and Krosigk, Belinavon and Warburton, Thomas K and Flechas, Maria Acosta and Aportela, Anthony and Calvet, Thomas and Cristella, Leonardo and Diaz, Daniel and Doglioni, Caterina and Galati, Maria Domenica and Khoda, Elham E and Fahim, Farah and Giri, Davide and Hawks, Benjamin and Hoang, Duc and Holzman, Burt and Hsu, Shih-Chieh and Jindariani, Sergo and Johnson, Iris and Kansal, Raghav and Kastner, Ryan and Katsavounidis, Erik and Krupa, Jeffrey and Li, Pan and Madireddy, Sandeep and Marx, Ethan and McCormack, Patrick and Meza, Andres and Mitrevski, Jovan and Mohammed, Mohammed Attia and Mokhtar, Farouk and Moreno, Eric and Nagu, Srishti and Narayan, Rohin and Palladino, Noah and Que, Zhiqiang and Park, Sang Eon and Ramamoorthy, Subramanian and Rankin, Dylan and Rothman, Simon and Sharma, Ashish and Summers, Sioni and Vischia, Pietro and Vlimant, Jean-Roch and Weng, Olivia}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Front Big Data}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{787421}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3389/fdata.2022.787421}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Joshua C. Agar. M3-Learning: Multifunctional Materials and Machine Learning </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/al-folio/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/al-folio/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/al-folio/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/al-folio/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/al-folio/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/al-folio/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>